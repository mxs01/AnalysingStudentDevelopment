%%%%%%%% ICML 2023 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

\usepackage{tikz}
\usepackage{enumitem}
% Corporate Design of the University of Tübingen
% Primary Colors
\definecolor{TUred}{RGB}{165,30,55}
\definecolor{TUgold}{RGB}{180,160,105}
\definecolor{TUdark}{RGB}{50,65,75}
\definecolor{TUgray}{RGB}{175,179,183}

% Secondary Colors
\definecolor{TUdarkblue}{RGB}{65,90,140}
\definecolor{TUblue}{RGB}{0,105,170}
\definecolor{TUlightblue}{RGB}{80,170,200}
\definecolor{TUlightgreen}{RGB}{130,185,160}
\definecolor{TUgreen}{RGB}{125,165,75}
\definecolor{TUdarkgreen}{RGB}{50,110,30}
\definecolor{TUocre}{RGB}{200,80,60}
\definecolor{TUviolet}{RGB}{175,110,150}
\definecolor{TUmauve}{RGB}{180,160,150}
\definecolor{TUbeige}{RGB}{215,180,105}
\definecolor{TUorange}{RGB}{210,150,0}
\definecolor{TUbrown}{RGB}{145,105,70}

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2023} with \usepackage[nohyperref]{icml2023} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

\usepackage[accepted]{icml2023}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref.
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Project Report Template for Data Literacy 2023/24}

\begin{document}

\twocolumn[
\icmltitle{A prediction and Analysis of the interplay between Graduate Statistics and Salary Prospects in the STEM Field}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2023
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Abdallah Abdul-Latif}{equal,first}
\icmlauthor{Lisa-Maria Fritsch}{equal,second}
\icmlauthor{Paul Kaifler}{equal,third}
\icmlauthor{Maximilian Schnitt}{equal,fourth}
\end{icmlauthorlist}

% fill in your matrikelnummer, email address, degree, for each group member
\icmlaffiliation{first}{Matrikelnummer 5977981, abdallah.abdul-latif@student.uni-tuebingen.de, MSc Computer Science}
\icmlaffiliation{second}{Matrikelnummer 4189024, lisa-maria.fritsch@student.uni-tuebingen.de, MSc Computer Science}
\icmlaffiliation{third}{Matrikelnummer 5993286, paul.kaifler@student.uni-tuebingen.de, Bsc Computer Science}
\icmlaffiliation{fourth}{Matrikelnummer 6040570, maximilian.schnitt@student.uni-tuebingen.de, BSc Computer Science}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention the equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

%Put your abstract here. Abstracts typically start with a sentence motivating why the subject is interesting. Then mention the data, methodology, or methods you are working with, and describe the results. 
\begin{abstract}
This paper investigates the role of expected salary in influencing the choice of academic majors among
students in the STEM field at the University of Tübingen.
The study focuses on the interplay among three key parameters: the enrollment of students, the expected salary, and the number of graduates.
Employing a Vector Autoregressive model, we can confidently predict the number of students for the upcoming semesters
and show that the expected salary plays a key role in making that prediction.
Furthermore, by manipulating the salary variable in our analysis, we observe a corresponding increase or decrease in the number of students.
This implies a sensitivity in enrollment trends to changes in expected salary, highlighting the potential impact of financial considerations on academic choices.

% Motivate the problem, situation, or topic you decided to work on. 
% Describe why it matters (is it of societal, economic, or scientific value?). 
% Outline the rest of the paper (use references, e.g.~to \Cref{sec:methods}: 
% What kind of data you are working with, how you analyze it, and what kind of conclusion you reached. 
% The point of the introduction is to make the reader want to read the rest of the paper.
\end{abstract}

\section{Introduction}\label{sec:intro}
In recent years, a growing number of high school graduates have chosen the path of higher education.
Science, technology, engineering, and mathematics, known as STEM, make up a large proportion of all students, although
this academic career is known for being one of the most demanding.
This paper aims to explore the potential influence of financial incentives.

The analysis is built on three underlying datasets.
The first dataset captures the historical enrollment figures of students at the University of Tübingen. 
It contains the total number of students for each semester, for all study programs. This dataset is maintained and published by the
\href{https://uni-tuebingen.de/einrichtungen/verwaltung/iv-studierende/studierendenabteilung/statistiken/}{Statistics Bureau of the University of Tübingen}.
The University of Tübingen makes a good candidate to discover potential structure in the number
of enrollments because STEM programs are strongly represented here. % TODO: I think mentioning the potential risk of BIAS could be in the Discussion-part
To quantify the salary expectations, a dataset from the \href{https://www-genesis.destatis.de/genesis//online?operation=table&code=62321-0001&bypass=true&levelindex=0&levelid=1702307320529#abreadcrumb}{Deutsches Statistisches Bundesamt} is used.
It contains the salary trend for all major industrial sectors in Germany. This dataset does not adjust for inflation,
therefore an additional \href{https://www-genesis.destatis.de/genesis//online?operation=table&code=61121-0001&bypass=true&levelindex=0&levelid=1706446467491#abreadcrumb}{dataset}
from the Deutsches Statistisches Bundesamt is used to account for that (\Cref{sec:methods:processing}). It contains the inflation rate in Germany for each year.
The number of students is also limited by a further parameter. Namely the number of people eligible for an academic career.
The \href{https://www.statistik-bw.de/BildungKultur/SchulenAllgem/LRt0302.jsp}{Statistisches Landesamt Baden-Württemberg} provides
data about high school graduates in Baden-Württemberg for every year. We will not take other states into account, under
the assumption that the number of students leaving Baden-Württemberg, to study elsewhere, cancels out with others moving to the University of Tübingen.

Our central contribution is a Vector autoregressive model (VAR) discussed in \Cref{sec:methods:var} that is built using just mentioned data. Combined with a
partial autocorrelation function (PACF) the optimal value for the lag
is determined, see \Cref{sec:methods:lag}, to ensure that relevant structure in the data is captured by the model.
After verifying that the VAR model functions as expected and testing the model on a test set, \Cref{fig:accuracy model}, we
can predict all three input time series. As we are only interested in the number of students enrolled and the development of the salary, our research is 
focused on these two instances.
This allows us to conclude in \Cref{sec:methods:causality} that salary has a significant impact on the amount of STEM students. Further, we can model different salary development scenarios, 
and see how the students would likely react (\Cref{sec:results}).


A repository containing the complete analyses and results can be found \href{https://github.com/mxs01/AnalysingStudentDevelopment}{here}.


% In this section, describe \emph{what you did}. Roughly speaking, 
% explain what data you worked with, how or from where it was collected, its structure, and size.
% Explain your analysis and any specific choices you made in it. Depending on the nature of your project,
% you may focus more or less on certain aspects. If you collect data yourself, explain the collection process in detail.
% If you downloaded data from the net, show an exploratory analysis that builds
% intuition for the data, and shows that you know the data well. 
% If you are doing a custom analysis, explain how it works and why it is the right choice.
% If you are using a standard tool, it may still help to briefly outline it. Cite relevant works. 
% You can use the \verb|\citep| and \verb|\citet| commands for this purpose \citep{mackay2003information}.


\section{Data and Methods}\label{sec:methods}

\begin{figure*}
    \includegraphics{fig/prediction_5.pdf}
    \caption{VAR model Prediction with optimal lag value of $5$ on the test data set. Standard error with confidence interval value $\alpha = 0.05$.}
    \label{fig:accuracy model}
\end{figure*}

\subsection{Data Processing}\label{sec:methods:processing}
Each data set used in the analysis had to be processed, to work for our analysis.
The university data is only available in PDF format to download. To process the data, it had
to be transformed into a more versatile format, using two steps. First, it has been transformed into CSV, which resulted in a corrupted file.
A custom-written parser was then used, to restore the original data structure.
In the year 2012, two years of high school graduates finished, due to the transition from G9 to G8 in
Baden-Württemberg. This outlier in the data had to be flattened out to ensure the VAR model could be fitted correctly.
The model uses the mean square error as a loss function, which makes outliers influence the data disproportionately.
Half the number of students from the year 2012 has been spread over the next four years to flatten the data.
The Deutsches Statistisches Bundesamt from which the average gross salary is obtained, does not account for inflation in its data set.
Since we need to maintain comparability between past years, the salary has been adjusted for a yearly cumulative inflation rate.


\subsection{Model creation}\label{sec:methods:var}
A vector autoregressive model is used to analyze relationships between multiple time series.
The model creates a linear combination for each prediction which can be expressed in a matrix-vector notation.
\begin{equation*}
    \resizebox{\linewidth}{!}{
        $\begin{bmatrix}
            S_{1,n}\\
            S_{2,n}\\
            \vdots \\
            S_{m,n}
        \end{bmatrix} = 
        \begin{bmatrix}
            C_{1,1} & C_{1,2} & \dots &C_{1,n-1}\\
            C_{2,1} & C_{2,2} &\dots & C_{2,n-1}\\
            \vdots & \vdots  & \ddots &\vdots\\
            C_{m,1} & C_{m,2} &\dots &C_{m,n-1}\\
        \end{bmatrix} \cdot
        \begin{bmatrix}
            S_{1,1} & S_{1,2} & \dots & S_{1,n-1}\\
            S_{2,1} & S_{2,2} & \dots & S_{2,n-1}\\
            \vdots & \vdots  & \ddots &\vdots\\
            S_{m,1} & S_{m,2} & \dots & S_{m,n-1}\\
        \end{bmatrix}+
        \begin{bmatrix}
            \epsilon_{1}\\
            \epsilon_{2}\\
            \vdots\\
            \epsilon_{n}\\
        \end{bmatrix}$%
    }
\end{equation*}
The $\epsilon$ vector approximates an error, which is induced by the model. One main benefit of the VAR model is that it also assumes
that $S_{i,j}$ is also influenced by $S_{k,l}$ $i,k \in \{1,\dots, m\}: i\neq k$ and $j,l \in \{1,\dots, n-1\}: j\neq l$. As mentioned in \citep{kot}
A VAR model has one major advantage, over other possible approaches, which is its simplicity. Therefore its results remain interpretable.
This model only uses one hyperparameter which describes the amount of past data that is used to make a prediction. This parameter is called the lag.
The vector autoregressive model heavily depends on the stationarity assumption which ensures that the stochastical process stays the same over time. 
In this context, this is assured by the following three axioms:
\begin{enumerate}[label=\Roman*]
    \item The mean $\mu$ is constant
    \item The standard deviation is constant
    \item There is no seasonality in the data
\end{enumerate}
Since we are only interested in predicting two time steps into the future, which is equivalent to one year,
we can safely assume that our data is stationary.


\subsection{Choosing lag}\label{sec:methods:lag}
To find the optimal hyperparameter we used two well-established methods, the PACF and information-based criteria. Particularly the AIC and 
BIC. The PACF only considers the impact of the previous data point $S_{n-1}$ on $S_{n}$ to build a $(1-\alpha)$ confidence interval.
We choose $\alpha = 5\%$ and get a 95\% Confidence Interval. The optimal value according to PACF is $3$.
\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c|c}
        & students & salary & graduates \\
        \hline
        Prediciton 1 & 0.704\% & 0.871\% & 2.658\% \\
        \hline
        Prediciton 2 & 2.786\% & 0.301\% & 0.286\%
    \end{tabular}
    \caption{Difference in percent between the true value and predicted value for students, salary, and graduates. Lag set to $3$.}
    \label{tab:resid1}
\end{table}
The percentage differences between the true values and the predicted ones, especially for the students, are quite high, see \Cref{tab:resid1}.
To get better results
the AIC and BIC are used to find a better lag for the hyperparameter $p$, which is the lag. The abbreviation AIC
stands for Akaike Information Criterion and tries to find an optimum between the complexity of the model and fitting the data.
This should prevent overfitting. 
BIC is short for Bayesian Information Criterion and penalizes more complex models.
Therefore BIC leads to less complicated models than the ones from AIC, which sets the two apart.
Both BIC and AIC return $6$ as an optimal lag value for our data set. Since we are focusing on predicting students, low errors in that domain
are more important to us. Minimizing these errors within the range from $3$ to $6$ leads to an optimal lag value of $5$.
\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c|c}
        & students & salary & graduates \\
        \hline
        Prediciton 1 & 0.484\% & 0.419\% & 0.111\% \\
        \hline
        Prediciton 2 & 1.346\% & 0.306\% & 0.939\%
    \end{tabular}
    \caption{Difference in percent between the true value and predicted value for students, salary, and graduates. Lag set to $5$.}
    \label{tab:resid2}
\end{table}

The percentage errors in \Cref{tab:resid2} show that there is a significant improvement in the prediction of student numbers
compared to the lag order of $3$ from \Cref{tab:resid1}.

\subsection{Test for causality}\label{sec:methods:causality}
To ensure that the model does not try to find structure in the data, where there is none, we applied the Granger causality test.
Granger causal implies that one time series is the result of another shifted time series.
In this case, we try to find out if e.g. the salary time series is just a shifted version of the student's or the graduate's time series.
The test does verifies this by using series $S_i$ and trying to insert data points from $S_j$ or $S_k$ $i \neq j\neq k$
to predict the outcome of the model. After inserting the data points a t-test and a F-test are performed. If both
tests return statistical significance, then we showed that $S_i$ could be expressed by a shifted input time series $S_j$ with $j\neq i$.
% tbd notebook 2
\textcolor{red}{TBD}


\subsection{Fitted model}\label{sec:methods:fit}
\begin{figure}
    \includegraphics{fig/params_Students.pdf}
    \caption{Coefficients of VAR model to predict students time-series
    for $t_0$. $t_{-1}$ to $t_{-5}$ are the values of each time series respectively at the lagged time step, which is equal to one semester.
    $t_{-1}$ is the most recent value.}
    \label{fig:student coefficients}
\end{figure}


With the correct lag chosen, the model fits the data by minimizing the mean square error.
The returned coefficients describe the impact of a specific lagged value from one time series
on predicting the next value. \Cref{fig:student coefficients} visualizes all coefficients
relevant for predicting the number of students in the next semester. 
Notably, salary is the most relevant information for the prediction. All five
coefficient values for each time step are non-zero, indicating a strong correlation.
Graduates, on the other hand, are not as relevant, recognizable by values close to zero.

The suggested lag value of $5$, earlier obtained in \Cref{sec:methods:lag} is retrievable as well.
The absolute value of the coefficient for predicting students on $t_{-5}$ is the third largest, adding
a lot of information to the model.

To further understand the data underlying correlations, one can look at the correlation matrix
of residuals in \Cref{tab:correlation matrix}.
This matrix describes the degree to which the model's errors, called residuals, are related to each other.
High correlations between errors can indicate a not fully captured underlying structure.
Values close to zero, like $-0.115$ between salary and graduates, indicate that the errors
in predicting the salary variable are not related to the errors in predicting the graduates variable.


\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c|c}
        & students & salary & graduates\\
        \hline
        students & 1.000 & -0.115 &  0.111\\
        \hline
        salary & -0.115 & 1.000000 & -0.902\\
        \hline
        graduates & 0.111 & -0.902 &  1.000\\
    \end{tabular}
    \caption{Correlation matrix of residuals using $5$ lags.}
    \label{tab:correlation matrix}
\end{table}

% This is the template for a figure from the original ICML submission pack. In lecture 10 we will discuss plotting in detail.
% Refer to this lecture on how to include figures in this text.
% 
% \begin{figure}[ht]
% \vskip 0.2in
% \begin{center}
% \centerline{\includegraphics[width=\columnwidth]{icml_numpapers}}
% \caption{Historical locations and number of accepted papers for International
% Machine Learning Conferences (ICML 1993 -- ICML 2008) and International
% Workshops on Machine Learning (ML 1988 -- ML 1992). At the time this figure was
% produced, the number of accepted papers for ICML 2008 was unknown and instead
% estimated.}
% \label{icml-historical}
% \end{center}
% \vskip -0.2in
% \end{figure}

\section{Results}\label{sec:results}
It is not possible to find a lag value that gives the best results for all three time series.
However one can set the optimal lag value such that it suits forecasting students best (\Cref{sec:methods:lag}).
With the obtained insights into the relation between the number of enrolled students, salary expectations, and number of graduates,
it is now possible to make predictions on different scenarios.

The training of the model stays set, and the whole dataset available is used. It is now possible to 
generate a new data set with a 10\% increase in salary expectations and set it as the new model input, \Cref{fig:altered salary}.
The observed change in the prediction supports the obtained results in \Cref{sec:methods:fit}. There is a significant
dependence between salary expectations and the number of students enrolled in STEM courses. As soon as the salary
increases, there is also an upward trend visible in student numbers. The observed change is not massive which can be explained
by the fact that the mass of students are students in higher semesters. The only direct major influence on
the total number of enrolled students is made by people deciding to start this year. There won't be a lot of people changing subjects
halfway through their academic careers.

This also explains the huge spike in predicting the average gross salary. In the first few semesters,
the amount of new students is not high enough, to capture the need for new people. Therefore the model suggests raising the
salary even higher, to accommodate for that.

\begin{figure}[H]
    \centering
    \includegraphics{fig/prediction_modified_10p_increase_lags_5.pdf}
    \caption{Predict the number of students enrolled in STEM courses using an increased salary by 10\%.}
    \label{fig:altered salary}
\end{figure}






% Use this section to briefly summarize the entire text. Highlight limitations and problems, 
% but also make clear statements where they are possible and supported by the analysis. 
\section{Discussion \& Conclusion}\label{sec:conclusion}
In our research, we used a vector autoregressive model to predict the amount of students in the next semester. 
We used the salary data from the past 15 years and data about high school graduates in Baden-Würrtemberg as a prior. We optimized our Model to the best possible capacity,
but there are strict limitations that can not be overcome. Vector autoregressive models are only capable of detecting linear patterns in the data.
This occurs, because we only have linear combinations, based on values $S_{i,j}$ and coefficients to scale those values. If we wanted to improve
our prediction we had to replace our model with other machine learning applications.
A promising approach for this could be to implement a Random Forest algorithm.\\
Our model on the other hand compensates for any potential lag in accuracy by being easily interpretable. Each parameter of the model influences exactly
one part of the predictions and is therefore transparent in its process.
Also worth mentioning is that our predictions are only based on three different inputs. There are certainly other 
variables impacting the number of students enrolled in courses at a university. Especially ones, that are not easily quantifiable and are subject to
personal preferences. However, we are confident that our selected set of data captures the main aspects, as our model performs great on the provided test set.


\section*{Contribution Statement}
Abdallah Abdul-Latif analyzed the optimal parameter lag and mapped courses to salary sectors.
Lisa-Maria Fritsch was responsible for data pre-processing.
Paul Kaifler fitted the model to the data and created visualizations.
Maximilian Schnitt parsed the university data and analyzed optimal parameter lag.
All authors jointly did the analyses of the data and wrote the text of the report.
% Max Mustermann collected and prepared data. Gabi Musterfrau and John Doe performed the data analysis. Jane Doe produced visualizations. All authors will jointly wrote the text of the report. Note that you, as a group, a collectively responsible for the report. Your contributions should be roughly equal in amount and difficulty.


% \section*{Notes} 

% Your entire report has a \textbf{hard page limit of 4 pages} excluding references. (I.e. any pages beyond page 4 must only contain references). Appendices are \emph{not} possible. But you can put additional material, like interactive visualizations or videos, on a githunb repo (use \href{https://github.com/pnkraemer/tueplots}{links} in your pdf to refer to them). Each report has to contain \textbf{at least three plots or visualizations}, and \textbf{cite at least two references}. More details about how to prepare the report, inclucing how to produce plots, cite correctly, and how to ideally structure your github repo, will be discussed in the lecture, where a rubric for the evaluation will also be provided.

% References


\bibliography{bibliography}
\bibliographystyle{icml2023}

\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
